data:
  batch_size: 32
  dataset_dir: './data/ETT'
  dataset_name: 'ETTh1'
  dataset_filename: './data/ETT/ETTh1.csv'
  task_type: 'M2M'
  freq: 'S'  # if freq=B in_channels_covar=7 if freq=S in_channels_covar=25
  target: 'OT'
  split_ratio: [0.6, 0.2, 0.2]
  num_workers: 0

model:
  in_lens: 720  # latter-hist_len=336
  label_lens: 48
  out_lens: 96 # [96, 192, 336, 720]M2M  [24, 48, 96, 192, 336, 720]S2S
  num_nodes: 7
  num_hidden: 512 # for 96,192 -512 ;for 336,720 num_hidden=256
  num_hidden_covar: 64
  num_hidden_temp_dec: 16 # final_decoder_hidden temporal decoder former(16)-latter(128)
  in_channels_covar: 25
  out_channels_covar: 4
  out_channels_dec: 32  # decoders' output  former 2 -32; latter 2 - 8
  num_layers_enc: 2
  num_layers_dec: 2
  drop_rate: 0.5 # for 96,192 drop_rate=0.5 ;for 336,720 drop_rate=0.3
  if_ln: True
  if_revin: True
  embed_type: 'timeF' # choosen from [timeF, fixed, learned]


train:
  lr: 0.000984894211777642  # 0.000984894211777642;  0.00003822279848104051
  epochs: 100
  patience: 3
  is_training: True
  model_id: 'ETTh1_720_96'
  model: 'TiDE'
  checkpoints: './checkpoints/TiDE/'
  do_predict: False
  itr: 1 # experiments time
  test_flop: False

test:
  predict_lens: [1, 3, 6, 12]
  test_flop: False
  save_epoch: 43